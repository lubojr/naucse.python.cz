{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is web scraping?",
    "- Machine reading of unstructured data from websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What&#39;s not web scraping?",
    "- Downloading data via API",
    "- Download of structured data (JSON, CSV, ...)",
    "- Crawling - crawling and indexing the entire website using its internal hyperlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Mirka Sp\u00e1\u010dilov\u00e1 evaluated the films",
    "\n",
    "&gt; When you die and your whole life passes before your eyes,",
    "&gt; Mirka Sp\u00e1\u010dilov\u00e1 will come and give it 60%",
    "\n",
    "Does Mirka Sp\u00e1\u010dilov\u00e1 really rate all films 60%? Is there any way to verify it?",
    "\n",
    "Michal Bl\u00e1ha downloaded a total of 1333 articles by Mirka Sp\u00e1\u010dilov\u00e1 with the evaluation of films from iDnes and created a table of films and their evaluation. Sixty percent got every third movie :-)",
    "\n",
    "<div>\n",
    "<img src=\"static/spacilova.png\"/>\n",
    "</div>\n",
    "\n",
    "https://www.michalblaha.cz/2017/10/filmova-kriticka-mirka-spacilova-v-cislech/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Price analysis on Czech e-shops",
    "\n",
    "Do you think we can trust the 80% discounts that most Czech e-shops offer during Black Friday events?",
    "\n",
    "In 2017, a month before Black Friday, Apify started monitoring the prices of all products in the largest Czech e-shops on a daily basis. In addition, they monitored the prices of Black Friday products 4 times a day during Black Friday.",
    "\n",
    "What did they find out? The average reported discount was around 30%, real around 20.",
    "Just increase the &quot;original price&quot; before the discount. There were also cases where you could buy goods more expensive, but with a bigger discount.",
    "\n",
    "The project has grown in the following years, so today we can download the extension to the browser and see for ourselves.",
    "\n",
    "\n",
    "<div>\n",
    "    <img src=\"static/hlidacshopu.png\"/>\n",
    "</div>\n",
    "<br />\n",
    "https://blog.apify.com/black-friday-po-%C4%8Desku-kouzla-se-slevami-c7c0d2e7eeaa\n",
    "\n",
    "https://medium.com/@jakubbalada/black-friday-2019-s-hl%C3%ADda%C4%8Dem-shop%C5%AF-9a3ddd352a8c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etika web scrapingu",
    "\n",
    "- Before you start web scraping, see if the site offers structured data for download or does not provide an API.",
    "- **Examples:**",
    "    - https://data.gov.cz/datov%C3%A9-sady?poskytovatel=%C4%8Cesk%C3%BD%20statistick%C3%BD%20%C3%BA%C5%99ad\n",
    "    - https://www.ncdc.noaa.gov/data-access\n",
    "    - https://www.mapakriminality.cz/data/\n",
    "    - http://opendata.praha.eu/dataset/meteostanice-chmi-api\n",
    "- Find out what rights you have to the data, do not publish the obtained data illegally",
    "- Approach the site to a reasonable extent, you are not trying to drop the page, but to get the data :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What a website is made of",
    "- ** HTML ** (HyperText Markup Language): structured page content (text and images)",
    "- ** CSS ** (Cascading Style Sheets): page layout adjustment",
    "- ** JavaScript **: interactivity of page content and layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML \n",
    "<div>\n",
    "    <img src=\"static/html.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It consists of HTML tags / tags, eg ``<img> ``",
    "- Most HTML tags are paired, eg ``<h2> `` and ``</h2> ``",
    "- Tags can have attributes that further specify what and how the tag will display",
    "- The class attribute is usually used to style a page, and we can often distinguish different parts of a page when webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS\n",
    "\n",
    "- Describes how to display html elements",
    "- Contains 2 parts: element selector and declaration block:",
    "\n",
    "```\n",
    "p.error {\n",
    "  color: red;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install lxml beautifulsoup4 selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: read_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just need to download the tables from the web, we can use the [Pandas] library (https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.read_html.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert tables from the Wikipedia page [List of countries of the world by alcohol consumption] (https://en.wikipedia.org/wiki/List_of_world_alcohol_in_alcohol) to dataframes using the function `read_html () `:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html (&#39;https://cs.wikipedia.org/wiki/Seznam_st%C3%A1t%C5%AF_sv%C4%9Bta_podle_spot%C5%99eby_alkoholu&#39;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st\u00e1t</th>\n",
       "      <th>evidov\u00e1no</th>\n",
       "      <th>neevidov\u00e1no</th>\n",
       "      <th>celkem</th>\n",
       "      <th>pivo</th>\n",
       "      <th>v\u00edno</th>\n",
       "      <th>destil\u00e1ty</th>\n",
       "      <th>ostatn\u00ed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\u010cesko</td>\n",
       "      <td>14.97</td>\n",
       "      <td>1.48</td>\n",
       "      <td>16.45</td>\n",
       "      <td>8.51</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ma\u010farsko</td>\n",
       "      <td>12.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.27</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rusko</td>\n",
       "      <td>11.03</td>\n",
       "      <td>4.73</td>\n",
       "      <td>15.76</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ukrajina</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.50</td>\n",
       "      <td>15.60</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estonsko</td>\n",
       "      <td>13.77</td>\n",
       "      <td>1.80</td>\n",
       "      <td>15.57</td>\n",
       "      <td>5.53</td>\n",
       "      <td>1.09</td>\n",
       "      <td>9.19</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       st\u00e1t  evidov\u00e1no  neevidov\u00e1no  celkem  pivo  v\u00edno  destil\u00e1ty  ostatn\u00ed\n",
       "0     \u010cesko      14.97         1.48   16.45  8.51  2.33       3.59     0.39\n",
       "1  Ma\u010farsko      12.27         4.00   16.27  4.42  4.94       3.02     0.14\n",
       "2     Rusko      11.03         4.73   15.76  3.65  0.10       6.88     0.34\n",
       "3  Ukrajina       8.10         7.50   15.60  2.69  0.58       5.21     0.02\n",
       "4  Estonsko      13.77         1.80   15.57  5.53  1.09       9.19     0.43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the WHO, the Czechia is the first! At least in average alcohol consumption in 2003-2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Po\u0159ad\u00ed</th>\n",
       "      <th>St\u00e1t</th>\n",
       "      <th>Spot\u0159eba v litrech</th>\n",
       "      <th>Rok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Francie</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rakousko</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Estonsko</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>N\u011bmecko</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Irsko</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Po\u0159ad\u00ed      St\u00e1t  Spot\u0159eba v litrech   Rok\n",
       "0       1   Francie                12.6  2011\n",
       "1       2  Rakousko                12.2  2009\n",
       "2       3  Estonsko                12.0  2011\n",
       "3       4   N\u011bmecko                11.7  2009\n",
       "4       5     Irsko                11.6  2011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the OECD, it looks a little different \ud83e\uddd0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Warning: ** The world is not ideal (that&#39;s why there is so much to drink in) and `read_html ()` is not always able to get tables. The command does not have to &quot;see&quot; the table at all, or it cannot deal with its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a table of current economic data from the website of the [Czech Statistical Office] (https://www.czso.cz/csu/czso/aktualniinformace), `https://www.czso.cz / csu / czso / aktualniinformace`.",
    "\n",
    "** Help **: If you see ugly characters in the dataframe, try to specify `encoding = &#39;utf-8&#39;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data we are looking for is not in the form of a table on the web, we must move to &quot;more drastic&quot; tools :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [BeautifulSoup] library (https://www.crummy.com/software/BeautifulSoup/) is used to extract data from HTML and XML files. It works with various parsers that analyze HTML files, and allows you to select the required HTML elements and work with them.",
    "\n",
    "Footnote: If you have a bigger project and need to go through dozens of e-shops, for example, look at the [Scrapy] library (http://docs.scrapy.org/en/latest/intro/overview.html), which is more suitable for similar tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load a sample html document from a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"static/html_doc.html\", \"r\") as f:\n",
    "    html_doc = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an object of type `BeautifulSoup`. The first argument is HTML data, the second is used to specify the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `prettify ()` method, we can print nicely formatted html:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can move around the object of type `BeautifulSoup` using tags.",
    "The first element of type title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>PyData Prague | pydata.cz</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of type `h1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1><a href=\"https://pydata.cz/\">pydata.cz</a></h1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element name of type `h1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parent element name (`parent` and` name` attributes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'div'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data uvnit\u0159 elementu `h1` (atribut [`string`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pydata.cz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of type `h2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 id=\"code-of-conduct\">Code of Conduct</h2>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item Id `h2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code-of-conduct'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h2['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find all tags of a given type, eg `find_all (&#39;a&#39;)` will find all links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://pydata.cz/\">pydata.cz</a>,\n",
       " <a class=\"pydata\" href=\"https://pydata.org/\">PyData</a>,\n",
       " <a href=\"https://numfocus.org/\">NumFOCUS</a>,\n",
       " <a class=\"pydata\" href=\"https://pydata.org/code-of-conduct/\">pydata.org/code-of-conduct/</a>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can browse the search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pydata.cz/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pydata.cz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don&#39;t have to search only by tag name, but also by their attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 id=\"pydata-prague\">PyData Prague</h1>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(id=\"pydata-prague\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we search by class, we can use `` soup.find (class = &quot;pydata&quot;) ``, because `` class`` is a keyword in Python. We have to use `` class_``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"pydata\" href=\"https://pydata.org/\">PyData</a>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_=\"pydata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write `` class`` as a key in the `` attrs`` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"pydata\" href=\"https://pydata.org/\">PyData</a>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(attrs={'class':'pydata'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the paragraph with the id `` description``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all links with class `` pydata``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "\n",
    "The [requests] library (https://requests.readthedocs.io/en/master/) is for HTTP queries. In our case, we will use it to retrieve the text of the website.",
    "\n",
    "HTTP requests can also be made using the standard Python library, but `requests` have a much more human interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pydata.cz/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the return status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Status codes] (https://cs.wikipedia.org/wiki/Stavov%C3%A9_k%C3%B3dy_HTTP) is divided into 5 groups:",
    "- 1xx - information answer",
    "- 2xx - success",
    "- 3xx - redirection",
    "- 4xx - probably the client",
    "- 5xx - server error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text method shows the source code of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup second: CSS selectors",
    "\n",
    "With the BeautifulSoup library we can [search CSS selectors] (https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors) using the `select` (show all elements) and` select_one` functions (find the first element)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will open an html document with the kin program. It is downloaded from https://dokina.tiscali.cz/program-kin, but since it could happen that there is nothing on the program today, we prefer to use the downloaded version. Of course, if there is something on the site, you can use `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"static/kina.html\", \"r\") as f:\n",
    "    html_doc = f.read()\n",
    "soup = BeautifulSoup(html_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to find all tags with the class `title` and we will list some of them:",
    "(For the sake of clarity, we do not list all of them completely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"title mb-0\">3Bobule</h4>,\n",
       " <h4 class=\"title mb-0\">Tich\u00e9 m\u00edsto: \u010c\u00e1st II</h4>,\n",
       " <h4 class=\"title mb-0\">V s\u00edti</h4>,\n",
       " <h4 class=\"title mb-0\">Princezna zaklet\u00e1 v \u010dase</h4>,\n",
       " <h4 class=\"title mb-0\">Bloodshot</h4>,\n",
       " <h3 class=\"title mb-0\">\n",
       " <a data-ga-action=\"cinema-detail\" data-ga-category=\"program-kin\" href=\"https://dokina.tiscali.cz/evropsky-dum-7435\" title=\"Profil kina\">Evropsk\u00fd d\u016fm</a>\n",
       " <a class=\"favourite-toggler\" data-ga-action=\"toggle-favorite-cinema\" data-ga-category=\"program-kin\" data-id=\"7435\" href=\"https://dokina.tiscali.cz/program-kin?movie_id=&amp;place_id=&amp;cinema_type=&amp;town_id=&amp;start=25-03-2020#\" title=\"P\u0159idat do obl\u00edben\u00fdch\"></a>\n",
       " </h3>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = soup.select('.title') \n",
    "titles[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find all tags of type `<h3 class=\"title mb-0\"> `and let&#39;s look at the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"title mb-0\">\n",
       "<a data-ga-action=\"cinema-detail\" data-ga-category=\"program-kin\" href=\"https://dokina.tiscali.cz/evropsky-dum-7435\" title=\"Profil kina\">Evropsk\u00fd d\u016fm</a>\n",
       "<a class=\"favourite-toggler\" data-ga-action=\"toggle-favorite-cinema\" data-ga-category=\"program-kin\" data-id=\"7435\" href=\"https://dokina.tiscali.cz/program-kin?movie_id=&amp;place_id=&amp;cinema_type=&amp;town_id=&amp;start=25-03-2020#\" title=\"P\u0159idat do obl\u00edben\u00fdch\"></a>\n",
       "</h3>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb0_titles = soup.select('h3.title.mb-0')\n",
    "mb0_titles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find all the tags with the class `title` inside the tags with the class` movie-item`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"title mb-0\">3Bobule</h4>,\n",
       " <h4 class=\"title mb-0\">Tich\u00e9 m\u00edsto: \u010c\u00e1st II</h4>,\n",
       " <h4 class=\"title mb-0\">V s\u00edti</h4>,\n",
       " <h4 class=\"title mb-0\">Princezna zaklet\u00e1 v \u010dase</h4>,\n",
       " <h4 class=\"title mb-0\">Bloodshot</h4>,\n",
       " <h4 class=\"title mb-0\">A d\u00fdchejte klidn\u011b</h4>,\n",
       " <h4 class=\"title mb-0\">Svi\u0148a</h4>,\n",
       " <h4 class=\"title mb-0\">Kr\u00e1l\u00ed\u010dek Jojo</h4>,\n",
       " <h4 class=\"title mb-0\">La belle saison</h4>,\n",
       " <h4 class=\"title mb-0\">V\u00fdjime\u010dn\u00ed</h4>,\n",
       " <h4 class=\"title mb-0\">La Llorona</h4>,\n",
       " <h4 class=\"title mb-0\">Morgiana</h4>,\n",
       " <h4 class=\"title mb-0\">No\u010dn\u00ed ostraha</h4>,\n",
       " <h4 class=\"title mb-0\">Vita and Virginia</h4>,\n",
       " <h4 class=\"title mb-0\">Volej m\u00e1mu</h4>,\n",
       " <h4 class=\"title mb-0\">\u010cas beznad\u011bje</h4>,\n",
       " <h4 class=\"title mb-0\">\u0160arlat\u00e1n</h4>,\n",
       " <h4 class=\"title mb-0\">\u017daluji!</h4>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.movie-item .title ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools in the browser",
    "\n",
    "Before we go through the page using Python, it&#39;s a good idea to look at its structure directly in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The source code of the page",
    "\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"static/FF_pagesource.png\" />\n",
    "<img src=\"static/chrome_pagesource.png\" /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Element / Inspect",
    "\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"static/FF_inspect.png\" />\n",
    "<br />\n",
    "<img src=\"static/Inspect.png\" /> \n",
    "</div>\n",
    "<br />\n",
    "<strong>Attention:</strong> The source code of the selected element may not match the code you download using Python. It may have been modified by JavaScript while in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer Tools",
    "\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"static/FF_dev.png\" />\n",
    "<br />\n",
    "<img src=\"static/chrome_dev.png\" /> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note: ** If you do not see anything in the Network tab, try refreshing the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example from (in) life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Extraction of data on the 20 best films according to CSFD **",
    "\n",
    "We want to create a table with the following columns:",
    "\n",
    "- Movie title",
    "- Average rating",
    "- Country of origin",
    "- Year of introduction",
    "- The lenght of the film",
    "- Director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is no universal guide to scraping. Usually, we try trial and error to see what works. Then the site updates and we can start again ... *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.csfd.cz/zebricky/nejlepsi-filmy/'\n",
    "# page rejects GET requests without User-Agent identification:",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36'}\n",
    "r = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:",
    "Look at the source code of the page. What elements will we look for on the page? And where can we find information about the director?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let&#39;s see what the elements of the `movie` class look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"film\" id=\"chart-2294\"><a href=\"/film/2294-vykoupeni-z-veznice-shawshank/\">Vykoupen\u00ed z v\u011bznice Shawshank</a> <span class=\"film-year\" dir=\"ltr\">(1994)</span></td>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.film')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more information about the movies, we need to get to the movie page. To do this we will need links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/film/2294-vykoupeni-z-veznice-shawshank/\">Vykoupen\u00ed z v\u011bznice Shawshank</a>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_links = soup.select (&#39;. film a&#39;)",
    "movie_links [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.csfd.cz/film/2294-vykoupeni-z-veznice-shawshank/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [&#39;https://www.csfd.cz&#39; + film [&#39;href&#39;] for film in film_links]",
    "links [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We&#39;ll save the movie titles straight away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vykoupen\u00ed z v\u011bznice Shawshank'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [film.text for film in film_links]",
    "names [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average rating can be found in the elements with the class `average`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"average\">95,3%</td>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.average')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95,3%'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hodnoceni = [aver.text for aver in soup.select('.average')]\n",
    "rated [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Info",
    "\n",
    "First we will try to find information about the first film:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(odkazy[0], headers=headers)\n",
    "film_soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USA, 1994, 142 min'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_soup.select_one('.origin').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span data-truncate=\"60\" itemprop=\"director\">\n",
       "<a href=\"/tvurce/2869-frank-darabont/\">Frank Darabont</a>\n",
       "</span>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_soup.find('span', {'itemprop': 'director'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank Darabont'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_soup.find('span', {'itemprop': 'director'}).a.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurrah! It works. We can do it with all the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Footnote: `re` is a standard library module for working with strings using regular expressions. In the following code, we will use it to divide a string by two different characters.",
    "\n",
    "We need to solve cases of type `166 min (Director&#39;s cut: 175 min, Alternative: 152 min)`, so we divide the text according to the characters &quot;,&quot; and &quot;(&quot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "land = []",
    "years = []",
    "lengths [[]",
    "reziseri = []",
    "for link in links:",
    "    r = requests.get(odkaz, headers=headers)\n",
    "    film_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    txt = film_soup.select_one('.origin').text\n",
    "origin, year, time, * remainder = re.split (&#39;, | \\ (&#39;, txt)",
    "    reziser = film_soup.find('span', {'itemprop': 'director'}).a.text\n",
    "zeme.append (puvod)",
    "roky.append (year)",
    "delky.append(case)",
    "reziseri.append (reziser)",
    "sleep (1) # we behave humanely :-)",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N\u00e1zev</th>\n",
       "      <th>P\u016fvod</th>\n",
       "      <th>Rok</th>\n",
       "      <th>Re\u017eie</th>\n",
       "      <th>D\u00e9lka</th>\n",
       "      <th>\u010cSFD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vykoupen\u00ed z v\u011bznice Shawshank</td>\n",
       "      <td>USA</td>\n",
       "      <td>1994</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>142 min</td>\n",
       "      <td>95,3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>USA</td>\n",
       "      <td>1994</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>142 min</td>\n",
       "      <td>94,5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zelen\u00e1 m\u00edle</td>\n",
       "      <td>USA</td>\n",
       "      <td>1999</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>188 min</td>\n",
       "      <td>92,8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P\u0159elet nad kuka\u010d\u010d\u00edm hn\u00edzdem</td>\n",
       "      <td>USA</td>\n",
       "      <td>1975</td>\n",
       "      <td>Milo\u0161 Forman</td>\n",
       "      <td>133 min</td>\n",
       "      <td>92,5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedm</td>\n",
       "      <td>USA</td>\n",
       "      <td>1995</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>127 min</td>\n",
       "      <td>92,4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           N\u00e1zev P\u016fvod    Rok            Re\u017eie     D\u00e9lka  \\\n",
       "0  Vykoupen\u00ed z v\u011bznice Shawshank   USA   1994   Frank Darabont   142 min   \n",
       "1                   Forrest Gump   USA   1994  Robert Zemeckis   142 min   \n",
       "2                    Zelen\u00e1 m\u00edle   USA   1999   Frank Darabont   188 min   \n",
       "3    P\u0159elet nad kuka\u010d\u010d\u00edm hn\u00edzdem   USA   1975     Milo\u0161 Forman   133 min   \n",
       "4                           Sedm   USA   1995    David Fincher   127 min   \n",
       "\n",
       "    \u010cSFD  \n",
       "0  95,3%  \n",
       "1  94,5%  \n",
       "2  92,8%  \n",
       "3  92,5%  \n",
       "4  92,4%  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filmy_df = pd.DataFrame (zip (names, countries, years, directors, lengths, ratings),",
    "columns = [&#39;Name&#39;,",
    "&#39;Origin&#39;,",
    "&#39;Year&#39;,",
    "&#39;Directing&#39;,",
    "&#39;Length&#39;,",
    "&#39;\u010cSFD&#39;])",
    "movies_df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a website uses JavaScript to generate content, we have two options:",
    "\n",
    "1. Understand what JavaScript does and arrange yourself accordingly",
    "2. Act like a browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example",
    "Race results Big&#39;s Backyard Ultra, [`https://my.raceresult.com/139372/#0_2C3B48`](https://my.raceresult.com/139372/#0_2C3B48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"static/bigdog.png\" >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://my.raceresult.com/139372/#0_2C3B48')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to find the word Gavin in the text of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text.find(\"Gavin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing. Where they went wrong? We&#39;ll print the source code of the page ... and the spreadsheet nowhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Developer tools - Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have data from only one website, we can use developer tools to find out what javascript does on the page. We are interested in where the site takes the data.",
    "\n",
    "Open the developer tools and click on the Network tab. If there is nothing on it, we refresh the page. Typically, we&#39;re interested in queries of `XMLHttpRequest` (XHR), which allow a site to retrieve data from a URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"static/bigdog2.png\">\n",
    "<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we see two queries of the XHR type, we take a closer look to find out which of them contains the searched data. We will copy the link address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"static/bigdog4.png\">\n",
    "<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"static/bigdog5.png\">\n",
    "<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://my2.raceresult.com/RRPublish/data/list.php?eventid=139372&key=3a52cf488ad3dfe5c994f6b203e7c2e8&listname=Result+Lists%7CLap+Details&page=results&contest=0&r=all&l=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '1', '7:35:18', '55:19', '04:40'],\n",
       " ['1', '2', '8:35:23', '55:24', '04:35'],\n",
       " ['1', '3', '9:34:25', '54:26', '05:33'],\n",
       " ['1', '4', '10:35:09', '55:10', '04:49'],\n",
       " ['1', '5', '11:33:55', '53:56', '06:03'],\n",
       " ['1', '6', '12:34:23', '54:24', '05:35'],\n",
       " ['1', '7', '13:33:35', '53:36', '06:23'],\n",
       " ['1', '8', '14:33:57', '53:58', '06:01'],\n",
       " ['1', '9', '15:34:07', '54:08', '05:51'],\n",
       " ['1', '10', '16:34:39', '54:40', '05:19'],\n",
       " ['1', '11', '17:35:17', '55:18', '04:41'],\n",
       " ['1', '12', '18:34:22', '54:23', '05:36'],\n",
       " ['1', '13', '19:25:29', '45:30', '14:29'],\n",
       " ['1', '14', '20:28:55', '48:56', '11:03'],\n",
       " ['1', '15', '21:30:22', '50:23', '09:36'],\n",
       " ['1', '16', '22:27:05', '47:06', '12:53'],\n",
       " ['1', '17', '23:28:05', '48:06', '11:53'],\n",
       " ['1', '18', '24:28:35', '48:36', '11:23'],\n",
       " ['1', '19', '25:27:17', '47:18', '12:41'],\n",
       " ['1', '20', '26:28:12', '48:13', '11:46'],\n",
       " ['1', '21', '27:28:15', '48:16', '11:43'],\n",
       " ['1', '22', '28:26:35', '46:36', '13:23'],\n",
       " ['1', '23', '29:26:29', '46:30', '13:29'],\n",
       " ['1', '24', '30:27:35', '47:36', '12:23'],\n",
       " ['1', '25', '31:34:26', '54:27', '05:32'],\n",
       " ['1', '26', '32:32:42', '52:43', '07:16'],\n",
       " ['1', '27', '33:32:27', '52:28', '07:31'],\n",
       " ['1', '28', '34:34:26', '54:27', '05:32'],\n",
       " ['1', '29', '35:33:34', '53:35', '06:24'],\n",
       " ['1', '30', '36:33:37', '53:38', '06:21'],\n",
       " ['1', '31', '37:33:08', '53:09', '06:50'],\n",
       " ['1', '32', '38:34:02', '54:03', '05:56'],\n",
       " ['1', '33', '39:33:41', '53:42', '06:17'],\n",
       " ['1', '34', '40:33:59', '54:00', '05:59'],\n",
       " ['1', '35', '41:33:41', '53:42', '06:17'],\n",
       " ['1', '36', '42:36:38', '56:39', '03:20'],\n",
       " ['1', '37', '43:34:18', '54:19', '05:40'],\n",
       " ['1', '38', '44:33:52', '53:53', '06:06'],\n",
       " ['1', '39', '45:30:33', '50:34', '09:25'],\n",
       " ['1', '40', '46:31:21', '51:22', '08:37']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['data']['#1_1///Gavin Woody///40Laps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mo\u017enost 2: Headless browsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Selenium ** is a library designed to automate web application testing. It lets you launch and control your browser, so you can do virtually anything you do on the web with it. Need to fill out forms automatically or download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options  \n",
    "#from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options() \n",
    "options.headless = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don&#39;t have a chromedriver or geckodriver (for Firefox), you can download them here:",
    "- [https://sites.google.com/a/chromium.org/chromedriver/home](https://sites.google.com/a/chromium.org/chromedriver/home)\n",
    "- [https://github.com/mozilla/geckodriver/releases](https://github.com/mozilla/geckodriver/releases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(options=options)\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "driver.get (&#39;https://my3.raceresult.com/139372/#0_2C3B48&#39;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"static/bigdog3.png\">\n",
    "<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the table with the class `MainTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # we wait 5 s if the table loads",
    "    table = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'MainTable'))) \n",
    "except TimeoutException: \n",
    "    print(\"Time out!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"a900b51a-9168-024d-ae19-5291d48f166d\", element=\"8744ffeb-6ae3-0b43-983b-24ebdf28152c\")>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = table.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #\n",
      "Measurement\n",
      "Lap Split\n",
      "Rest Time\n",
      "  1\n",
      "Gavin Woody\n",
      "40Laps\n",
      "1 7:35:18 55:19 04:40  \n",
      "2 8:35:23 55:24 04:35  \n",
      "3 9:34:25 54:26 05:33  \n",
      "4 10:35:09 55:10 04:49  \n",
      "5 11:33:55 53:56 06:03  \n",
      "6 12:34:23 54:24 05:35  \n",
      "7 13:33:35 53:36 06:23  \n",
      "8 14:33:57 53:58 06:01  \n",
      "9 15:34:07 54:08 05:51  \n",
      "10 16:34:39 54:40 05:19  \n",
      "11 17:35:17 55:18 04:41  \n",
      "12 18:34:22 54:23 05:36  \n",
      "13 19:25:29 45:30 14:29  \n",
      "14 20:28:55 48:56 11:03  \n",
      "15 21:30:22 50:23 09:36  \n",
      "16 22:27:05 47:06 12:53  \n",
      "17 23:28:05 48:06 11:53  \n",
      "18 24:28:35 48:36 11:23  \n",
      "19 25:27:17 47:18 12:41  \n",
      "20 26:28:12 48:13 11:46  \n",
      "21 27:28:15 48:16 11:43  \n",
      "22 28:26:35 46:36 13:23  \n",
      "23 29:26:29 46:30 13:29  \n",
      "24 30:27:35 47:36 12:23  \n",
      "25 31:34:26 54:27 05:32  \n",
      "26 32:32:42 52:43 07:16  \n",
      "27 33:32:27 52:28 07:31  \n",
      "28 34:34:26 54:27 05:32  \n",
      "29 35:33:34 53:35 06:24  \n",
      "30 36:33:37 53:38 06:21  \n",
      "31 37:33:08 53:09 06:50  \n",
      "32 38:34:02 54:03 05:56  \n",
      "33 39:33:41 53:42 06:17  \n",
      "34 40:33:59 54:00 05:59  \n",
      "35 41:33:41 53:42 06:17  \n",
      "36 42:36:38 56:39 03:20  \n",
      "37 43:34:18 54:19\n"
     ]
    }
   ],
   "source": [
    "print(txt[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## In conclusion",
    "\n",
    "We learned how to get data even without API or CSV files. But we must not forget to comply with laws and ethics. Always try webscraping as a last resort, just the slightest change on the page and your procedure will stop working."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}