{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework implementation - fish regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "np.random.seed (42) # make it all work out the same",
    "\n",
    "__ = 0 # ignore, it also serves as free space for completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data using pandas, select the required columns, convert everything to numeric values.",
    "\n",
    "* (You will need [get_dummies] (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html), which encodes categorical values using one hot encoding (using zeros and ones (Note ** dummies ** because we will get auxiliary variables (columns), which are called ** dummy variables **.) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_data = pd.read_csv(\"fish_data.csv\", index_col=0)\n",
    "\n",
    "# enter the code",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the column you will use as the response (** Weight **). Store the columns you will use as flags in the ** X ** variable and the response column in the ** y ** variable.",
    "\n",
    "* In machine learning theory, model inputs (flags, input variables) are typically denoted by the letter X and outputs by the letter y. This is often how variables in code are also called. X represents an array (or table), where each row corresponds to one data sample and each column to one flag (input variable). y is a vector, or one column with a response. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete flag selection and response",
    "y = __",
    "X = __ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Division of data into training and testing. Note that we have different species of fish in the data, what to watch out for?",
    "\n",
    "* Method [train_test_split] (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test%20split#sklearn.model_selection.train_test_split) distributes data to us at random and test kit. The size of the test set can be specified by the test_size parameter, its default value is 0.25, ie 25%. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# complete the division into test and training data",
    "# X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose several regression models and try to use them.",
    "\n",
    "For today you can try:",
    "\n",
    "  - [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) \n",
    " \n",
    "  - [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n",
    "      + hyperparametry: \n",
    "          * alpha, float, default=1.0 \n",
    " \n",
    "- [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)        \n",
    "     + hyperparametry:\n",
    "          * kernel, default rbf, one of \u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmoid\u2019\n",
    "          * C, float, optional (default=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning: what are those * hyper-parameters *?",
    "\n",
    "For the examples with black boxes in the first hour, we (behind your back) helped each other a few times and",
    "we passed some parameters to the box at the beginning. This is because the box often allows the user to configure it. In box terminology, we can imagine that the box has various levers that can be adjusted. These levers are used to set the so-called ** hyper-parameters ** of the model. All the models you will find in the Scikit-learn library have some default settings and will be used without having to deal with setting these hyper-parameters.",
    "If the model does not give a satisfactory result, you can try to adjust these parameters, such as trying several different settings and comparing the value of the metric on the test set.",
    "\n",
    "In the list above we have some hyperparameters listed. Parameters are often related to regularization (above * alpha *, * C *). ** Regularization ** means that the model, in addition to trying to fit the data (giving the correct answers), takes some other criterion into account. Typically, this criterion makes sure that the output of the model does not amplify much, etc. Like you said in the example with the landscape, you choose the solution so that it is * smooth *, * nice *, * corresponds to the usual * landscapes.",
    "\n",
    "The model selection process, including its parameters, is called ** model selection **, in the Scikit-learn library you will find tools that can help you, under the heading [Model selection] (https://scikit-learn.org/stable/model_selection.html )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, SGDRegressor  \n",
    "from sklearn.svm import SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don&#39;t be afraid to change the list or try other parameter values",
    "model_zoo = [",
    "    LinearRegression(),\n",
    "Lasso (alpha = 1.0),",
    "Lasso (alpha = 0.5),",
    "    SVR(kernel=\"rbf\"),\n",
    "    SVR(kernel=\"poly\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The `fit` method is used for training (fitting), the` predict` method is used for prediction for new patterns.",
    "```\n",
    "  model.fit(X_train, y_train)\n",
    "  pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "+ You don&#39;t have to program the metric, you have `mean_absolute_error`,` mean_squared_error` and `r2_score`.",
    "```\n",
    "  metrika = mean_absolute_error(y_test, pred)\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def ml_game(X_train, y_train, X_test, y_test, model):\n",
    "&quot;&quot; &quot;1. Practices the model on the training set.",
    "2. Calculates and writes metric values on both the training and test sets.",
    "returns learned model",
    "    \"\"\" \n",
    "        \n",
    "# fill in the code according to the points above",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just uncomment",
    "\n",
    "#trained_models = []\n",
    "#for model in model_zoo: \n",
    "#    ml_game(X_train, y_train, X_test, y_test, model)\n",
    "#    trained_models.append(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned several models. Now think about the moment you would choose and why.",
    "Let&#39;s call it `best_model`. You can even try playing with hyperparameters and choose another setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the order of the model you selected",
    "\n",
    "# best_model = trained_models[__]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And beware, surprise ... another test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divided the data into training and testing. We used the training to learn the model.",
    "** But beware! ** We used the test set to select the model. The metric on the test set is us",
    "does not give an independent estimate of how our model will behave on unknown data. He was chosen so",
    "to give good results on the test set.",
    "\n",
    "\n",
    "The test set serves as an estimate of the generalization capabilities of the model. But it should not be used in learning,",
    "even when selecting a model. The part that we separate into &quot;testing&quot; for model selection purposes is called correctly",
    "** validation ** set.",
    "** Caution: ** However, if we have used this validation set to select a model, we must not use it to evaluate the generalization capabilities of this model.",
    "\n",
    "And so now comes the real test data, load it from the `fish_data_test.csv` file. If you scaled the data when creating the model, don&#39;t forget to resize the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"fish_data_test.csv\", index_col=0)\n",
    "test_data = pd.get_dummies(test_data.drop(columns=[\"ID\"]))\n",
    "\n",
    "y_real_test = test_data[\"Weight\"]\n",
    "X_real_test = test_data.drop(columns=[\"Weight\"])\n",
    "\n",
    "#y_pred_test = best_model.predict(X_real_test)\n",
    "\n",
    "#print(f\"MAE {mean_absolute_error(y_real_test, y_pred_test):.3f}\")\n",
    "#print(f\"MSE {mean_squared_error(y_real_test, y_pred_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for weight, predicted_weight in zip(y_real_test, y_pred_test):\n",
    "#    print(f\"{weight:>10.1f}     {predicted_weight:>10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ To give you an idea, let&#39;s see the dependence of the weight of the fish on the length Length3. We will show separately for different species, for example for Pike and Roach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_hotovy_prechozi_kod = False",
    "if mam_hotovy_prechozi_kod:",
    "    is_pike = test_data[\"Species_Bream\"] == 1\n",
    "    pike = test_data[is_pike].sort_values(by=[\"Length3\"])\n",
    "    pike_weights = pike[\"Weight\"]\n",
    "    pike_length3 = pike[\"Length3\"]\n",
    "    X_pike = scaler.transform(pike.drop(columns=[\"Weight\"]))\n",
    "    \n",
    "    predicted_pike_weights = best_model.predict(X_pike)\n",
    "\n",
    "    is_roach = test_data[\"Species_Roach\"] == 1\n",
    "    roach = test_data[is_roach].sort_values(by=[\"Length3\"])\n",
    "    roach_weights = roach[\"Weight\"]\n",
    "    roach_length3 = roach[\"Length3\"]\n",
    "    X_roach = scaler.transform(roach.drop(columns=[\"Weight\"]))\n",
    "    \n",
    "    predicted_roach_weights = best_model.predict(X_roach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt",
    "\n",
    "if mam_hotovy_prechozi_kod:",
    "    fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "    ax[0].scatter(pike_length3, pike_weights, label=\"true weight\");\n",
    "    ax[0].plot(pike_length3, predicted_pike_weights, label=\"prediction\");\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].scatter(roach_length3, roach_weights, label=\"true weight\");\n",
    "    ax[1].plot(roach_length3, predicted_roach_weights, label=\"prediction\");\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}