{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification",
    "\n",
    "\n",
    "So far, we have only dealt with regression problems. However, teacher learning involves two main groups of tasks - regression tasks and classification tasks.",
    "\n",
    "While for regression problems the output of the model is a continuous value (float),",
    "in classification tasks, the output of the model is a class indicator.",
    "\n",
    "Let&#39;s stick to our fish market and set an example. The task of predicting fish weight was a regression task,",
    "we predicted a continuous value.",
    "If we want to predict the species of fish (Perch - * perch *, Roach - * roach *, Pike - * pike *, ...), it is a prediction of a categorical value, ie a classification.",
    "\n",
    "Classification problems have slightly different properties and logic than regression problems, so there are models directly designed for such problems. They are called classifiers.",
    "\n",
    "But first we will try to look at the task of classification from the perspective we already know, that is, from the perspective of the landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data](static/ryby.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>9.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.2044</td>\n",
       "      <td>1.1484</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>13.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows \u00d7 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Weight  Length1  Length2  Length3   Height   Width   ID\n",
       "0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200    0\n",
       "1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056    1\n",
       "2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961    2\n",
       "3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555    3\n",
       "4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340    4\n",
       "..      ...     ...      ...      ...      ...      ...     ...  ...\n",
       "153   Smelt     9.8     11.4     12.0     13.2   2.2044  1.1484  153\n",
       "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936  154\n",
       "155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690  155\n",
       "156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558  156\n",
       "158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792  158\n",
       "\n",
       "[123 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# na\u010deteme si data",
    "import pandas as pd \n",
    "import numpy as np \n",
    "np.random.seed (2020) # random classifier settings",
    "\n",
    "data = pd.read_csv(\"static/fish_data.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:",
    "   \n",
    "The most common species of fish is * Perch *. Our goal is to create a classifier that returns information for specified measures (weight, different lengths and widths), whether it is a perch or another species. (So for simplicity, we only have two classes, ** Perch ** and ** others **.)",
    "\n",
    "+ Could you fit this task to the landscape? What could be the coordinates and what the altitude is?",
    "\n",
    "+ If you successfully dealt with the previous question, you can use one of the regression models for classification (yes, it probably won&#39;t be ideal when it comes to classification, but let&#39;s try what we already know first). But what will be the value of the response and how will we interpret it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again bring some basic offer of classification models:",
    "   \n",
    "+ [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "\n",
    "+ [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "    \n",
    "+ [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "   - n_estimators, integer, optional (default=100)\n",
    "   \n",
    "+ [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "     - C, float, optional (default=1.0)\n",
    "     - kernelstring, optional (default=\u2019rbf\u2019)\n",
    "     \n",
    "+ [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:",
    "Choose one model and try to train for fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let&#39;s prepare the data",
    "y = data[\"Species\"] == \"Perch\"\n",
    "y = y.astype(int)",
    "X = data.drop(columns=[\"ID\", \"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let&#39;s take a classifier",
    "# you can change",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let&#39;s divide into a training and validation set",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the validation set",
    "pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skute\u010dn\u00e1 t\u0159\u00edda:  Predikce:\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "1                1          OK\n",
      "0                0          OK\n",
      "1                1          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "1                0          X\n",
      "0                0          OK\n",
      "1                0          X\n",
      "0                0          OK\n",
      "1                0          X\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "1                1          OK\n",
      "0                0          OK\n",
      "0                1          X\n",
      "0                1          X\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "1                1          OK\n",
      "1                0          X\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "0                0          OK\n",
      "Po\u010det chyb: 6\n"
     ]
    }
   ],
   "source": [
    "print (&quot;Real class: Prediction:&quot;)",
    "for true, predicted in zip(y_test, pred):\n",
    "    print(f\"{true:<15}  {predicted:<10} {'OK' if true == predicted else 'X'}\")\n",
    "\n",
    "print (f &quot;Number of errors: {sum (y_test! = before)}&quot;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:",
    "\n",
    "+ It is probably clear that regression metrics are not very suitable for classification problems. What would you use as a metric",
    "for the classification task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4:",
    "\n",
    "- One option is to compare the percentage of successfully classified patterns. In our case, it will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u00dasp\u011b\u0161nost: 80.65 %\n"
     ]
    }
   ],
   "source": [
    "print (f &quot;Success: {100 * sum (y_test == before) / len (y_test):. 2f}%&quot;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success is not entirely bad, knowing the type of fish by size is not an easy task.",
    "\n",
    "But imagine that we have a data set with 100 fish, 95 of which will be perch (Perch type). Will a classifier with this success rate (the same as we came out) feel good or not? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5:",
    "\n",
    "We will first go through the classification metrics. If you are studying alone, study the chapter on classification metrics and then return to this exercise.",
    "\n",
    "Choose a metric for our task and try to find the best classifier possible. Then load the test set and see what your classifier gives the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve date",
    "test_data = pd.read_csv(\"static/fish_data_test.csv\", index_col=0)\n",
    "y_real_test = test_data[\"Species\"] == \"Perch\"\n",
    "y_real_test = y_real_test.astype(int)\n",
    "X_real_test = test_data.drop(columns=[\"ID\", \"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to learn different models and choose the best one",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# try to learn different models and choose the best one",
    "models = {\n",
    "    \"nearest neighbors\": KNeighborsClassifier(),\n",
    "    \"tree\": DecisionTreeClassifier(),\n",
    "    \"forest\": RandomForestClassifier(),\n",
    "    \"svc\": SVC()\n",
    "}\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction",
    "# model = models[...]\n",
    "test_pred = model.predict(X_real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skute\u010dn\u00e1 t\u0159\u00edda:  Predikce:\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                1          X\n",
      "0                1          X\n",
      "0                1          X\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                1          X\n",
      "0                1          X\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "1                0          X\n",
      "1                0          X\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "1                0          X\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "1                1          OK\n",
      "1                0          X\n",
      "1                0          X\n",
      "1                0          X\n",
      "1                0          X\n",
      "1                0          X\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "0                0          OK\n",
      "Po\u010det chyb: 13\n",
      "\u00dasp\u011b\u0161nost: 63.89 %\n"
     ]
    }
   ],
   "source": [
    "# try adding the selected metric",
    "print (f &quot;Real class: Prediction:&quot;)",
    "for true, predicted in zip(y_real_test, test_pred):\n",
    "    print(f\"{true:<15}  {predicted:<10} {'OK' if true == predicted else 'X'}\")\n",
    "\n",
    "print (f &quot;Number of errors: {sum (y_real_test! = test_pred)}&quot;)",
    "print (f &quot;Success: {100 * sum (y_real_test == test_pred) / len (y_real_test):. 2f}%&quot;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}